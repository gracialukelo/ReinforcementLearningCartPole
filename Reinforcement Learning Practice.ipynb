{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accaa0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0afd650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4829f8",
   "metadata": {},
   "source": [
    "### 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a63c0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv # vec multiple environments\n",
    "from stable_baselines3.common.evaluation import evaluate_policy  # test how it performs\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd01085-b0de-43a4-bf16-7ea7f50a189a",
   "metadata": {},
   "source": [
    "### 2. Load Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab250b7f-ec8a-4e8a-a063-4fd143faf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CartPole-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee7e261-5318-4223-9dde-40bd41393e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v1>>>>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle eine Environment\n",
    "env = gym.make(environment_name, render_mode=\"rgb_array\")\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46014784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.04489554, -0.02543845, -0.0155447 , -0.0231913 ], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.reset() setzt die Umgebung zur체ck und gibt ihren Anfangszustand zur체ck.\n",
    "obs = env.reset() \n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47c9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4002616e+00, -1.1087469e+38,  2.4129659e-01,  2.2514813e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.observation_space.sample() gibt einen zuf채lligen Zustand aus dem Beobachtungsraum der Umgebung zur체ck\n",
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3371d86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40729681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_environment(env, figsize=(5,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    img = env.render()\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfe2f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_environment(env)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f02872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9b4997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample() # 0 oder 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73a16b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.04843314,  0.17580394, -0.04200684, -0.26930413], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Laut OpenAI:\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    truncated, um anzuzeigen, ob der Schritt aufgrund einer Zeitbegrenzung abgeschnitten wurde.\n",
    "\"\"\"\n",
    "env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e365df9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:2.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:3.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:4.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:5.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:6.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:7.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:8.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:9.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:10.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:11.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:12.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:13.0\n",
      "Reward:1.0\n",
      "Episode:1 Score:14.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:1.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:2.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:3.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:4.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:5.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:6.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:7.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:8.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:9.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:10.0\n",
      "Reward:1.0\n",
      "Episode:2 Score:11.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:1.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:2.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:3.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:4.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:5.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:6.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:7.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:8.0\n",
      "Reward:1.0\n",
      "Episode:3 Score:9.0\n",
      "Reward:1.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "for episode in range(1, episodes+1):\n",
    "    obs, info = env.reset()\n",
    "    terminated= False\n",
    "    score = 0\n",
    "    \n",
    "    while not terminated:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        score+=reward\n",
    "        print('Episode:{} Score:{}'.format(episode, score))\n",
    "        print('Reward:{}'.format(reward))\n",
    "env.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "677b1ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1.0.\n",
      "Der Score: 1.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 2.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 3.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 4.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 5.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 6.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 7.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 8.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 9.0.\n",
      "Reward: 1.0.\n",
      "Der Score: 10.0.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name, render_mode=\"rgb_array\")\n",
    "observation, info = env.reset(seed=42)\n",
    "score = 0\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()  # this is where you would insert your policy\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    score+=reward\n",
    "    print(f\"Reward: {reward}.\")\n",
    "    print(f\"Der Score: {score}.\")  \n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732a5990",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2ae472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-push cart to left, 1-push cart to the right\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5daa463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.2017548e+00,  2.8516898e+38, -3.3568960e-01, -2.9268933e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4bdf845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a955e271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot_environment(env)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c699a",
   "metadata": {},
   "source": [
    "### 3. Train the RL Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50245719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training/Logs'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29698ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "434ee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPO??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "873809d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 5944 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4217        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009269951 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00354     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.59        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3842        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009224029 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3690        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011171997 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3608        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007880629 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3558        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008320581 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3523        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005349471 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 62.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3493        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004181737 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3454        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005652358 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3440         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075640995 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.8          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x299d44c90>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154bb4f",
   "metadata": {},
   "source": [
    "### 4. Save and reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd69360",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', 'PPO_Molde_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1788c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "638b3e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece815ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7509c6",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff8733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean_reward, std_reward \n",
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558f6ff",
   "metadata": {},
   "source": [
    "### 6. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06f33ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info [{'episode': {'r': 500.0, 'l': 500, 't': 408.506056}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.11621635, -0.00104511,  0.00163921, -0.0142077 ], dtype=float32)}]\n",
      "Info [{'episode': {'r': 500.0, 'l': 500, 't': 416.204314}, 'TimeLimit.truncated': True, 'terminal_observation': array([-0.06530925,  0.00518817,  0.00177661, -0.01586084], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render('human')\n",
    "    if dones:\n",
    "        print(f\"Info: {info}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd49d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8efcf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b789cf2",
   "metadata": {},
   "source": [
    "### 7. viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcab5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ca7938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training/Logs/PPO_1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9446ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\r\n",
      "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4b351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
